---
id: glossary
title: 	Glossary
---

## __Aligning on a Common Language__

Here are a number of common terms used. Refer to this glossary if you ever have a question on a term, and if you see a term that is missing, let us know!


### __AI__

See [Artificial Intelligence](#artificial-intelligence).

### __AI Systems__

AI systems are software (and possibly also hardware) systems designed by humans that, given a complex goal, act in the physical or digital dimension by perceiving their environment through data acquisition, interpreting the collected structured or unstructured data, reasoning on the knowledge, or processing the information, derived from this data and deciding an action(s) to take to achieve a given goal.

See [Artificial Intelligence](#artificial-intelligence).

### __Artificial Intelligence__

Artificial intelligence is wide-ranging branch of computer science concerned with building smart machines capable of performing tasks that typically require human intelligence. AI is the parent field with subfields like machine learning, deep learning, NLP, computer vision and more.

Also known as: AI

### __Advanced Technology Collaborative__

A division of Optum Care that provides the analysis of the fitness of advanced technologies to business units and helps develop pilot applications in new technologies.  See [http://atc.optum.com](http://atc.optum.com) to learn more.

Also known as: ATC

### __Azure Databricks__

Azure Databricks is an Apache Spark-based platform for AI and data analytics and is available to Optum teams via [OptumIQ Studio Workbench](#optumiq-studio-workbench). It allows you to create Spark clusters and manage workflows through an user interface and supports Python, Scala, R, Java, and SQL, as well as data science frameworks and libraries including TensorFlow, PyTorch, and scikit-learn.

Also known as: Databricks

### __Azure Machine Learning__

Azure Machine Learning (AzureML) is an Azure AI service offering from Microsoft that empowers developers and data scientists to build, train, and deploy machine learning models faster by providing robust capabilities to support the end-to-end ML lifecycle.

Also known as: AzureML

### __AzureML__

See [Azure Machine Learning](#azure-machine-learning).

### __Cerebras__

A pioneering solution of using [Wafer Scale Integration](#wafer-scale-integration) to deliver massively parallel computing systems.  The Cerebras Wafer-Scale Engine (WSE) can deliver 400,000 compute cores optimized for solving linear algebra for training deep neural networks. The second generation solution, [Cerebras CS-2](https://cerebras.net/product/), has 850,000 AI-optimized cores. 

### __Databricks__

See [Azure Databricks](#azure-databricks).

### __Explainable AI__

AI predictions where the question of "why did you recommend this" is available in a natural language text description.  Unlike in speech or image processing, where a probability of classification is used, healthcare providers demand a clear explanation of why specific recommendations are made.  These requirements typically rule out machine learning models that don't have
clear explanation of why specific recommendations are made.  The solution is to use machine learning to train weights in a knowledge
graph so that the traversal of a concept graph with labels can bind recommendations to explanations.

### __GPU__

See [Graphics Processing Unit](#graphics-processing-unit).

### __Graphcore__

Graphcore is a company that is building VLSI chips that specialize in graph traversal.  Their type of chip is
called an [Intelligent Processing Unit](#intelligent-processing-unit) (IPU).  A Graphcore chip has a retail price of $10K but we can rent instances of these chips on Azure by the hour.  IPUs are strong at building machine learning models on sparse models.

### __Graphics Processing Unit__

A specialized electronic circuit designed to rapidly manipulate numerical matrices.  GPUs are used to accelerate the creation of images in a frame buffer intended for output to a display device. GPUs are used in embedded systems, mobile phones, personal computers, workstations, and game consoles.  Within Optum GPUs are used to accelerate the creation of machine learning models.

Also known as: GPU, GPUs

### __Intelligent Processing Unit__

A massively parallel computing system optimized for graph analysis.  IPUs are the primary product of [Graphcore](#graphcore).

Also known as: IPU

### __IPU__

See [Intelligent Processing Unit](#intelligent-processing-unit).

### __IQStudio__

See [OptumIQ Studio Workbench](#optumiq-studio-workbench).

### __Machine Learning__

The study of computer algorithms that improve automatically through experience.

Also known as: ML

### __ML__

See [Machine Learning](#machine-learning).

<!-- ### __ML Engineering__


### __ML Lifecycle__


### __MLOps__



### __ModelOps__

See [MLOps](#MLOps).

-->

### __Model Management__

A new category of technologies and processes that help organizations consistently and safely develop, validate, deliver, and monitor models that create a competitive advantage.

### __OptumIQ Studio Workbench__

The OptumIQ Studio Workbench is a self-service platform that provides analytic developers with secure, compliant, and modern tools for use in Microsoft Azure. The platform supports the entire lifecycle of analytic development, from training to production deployment, all while leveraging the scale, managed services, and pricing of the public cloud.

Also known as: IQStudio, IQS, Workbench

### __Sparse Models__

Models where only a small fraction of parameters are non-zero â€“ arise frequently in machine learning.  GPUs tend to work
well with dense models.  IPUs may be more cost-effective with dense models.

### __Wafer-scale Integration__

A system of building very-large integrated circuit networks that use an entire silicon wafer to produce a single "super-chip". Combining large size and reduced packaging, WSI was expected to lead to dramatically reduced costs for some systems, notably massively parallel supercomputers. [Cerebras Systems](https://www.cerebras.net/) is one company offering a 850,000 core system that would be ideal for parallel graph computation.

Also known as: WSI

### __Workbench__

See [OptumIQ Studio Workbench](#optumiq-studio-workbench).

### __XGBoost__

XGBoost is an open-source software library which provides a gradient boosting framework for a number of common programming languages used by the data science community.